{
  "name": "nodetool-lib-audio",
  "description": "Nodetool Audio nodes",
  "version": "0.6.2-rc.15",
  "authors": [
    "Matthias Georgi <matti.georgi@gmail.com>"
  ],
  "repo_id": "",
  "nodes": [
    {
      "title": "Bitcrush",
      "description": "Applies a bitcrushing effect to an audio file, reducing bit depth and/or sample rate.\n    audio, effect, distortion\n\n    Use cases:\n    - Create lo-fi or retro-style audio effects\n    - Simulate vintage digital audio equipment\n    - Add digital distortion and artifacts to sounds",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.Bitcrush",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "bit_depth",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Bit Depth",
          "description": "The bit depth to reduce the audio to. Lower values create more distortion.",
          "min": 1.0,
          "max": 16.0
        },
        {
          "name": "sample_rate_reduction",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Sample Rate Reduction",
          "description": "Factor by which to reduce the sample rate. Higher values create more aliasing.",
          "min": 1.0,
          "max": 100.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "bit_depth",
        "sample_rate_reduction"
      ]
    },
    {
      "title": "Compress",
      "description": "Applies dynamic range compression to an audio file.\n    audio, effect, dynamics\n\n    Use cases:\n    - Even out volume levels in a recording\n    - Increase perceived loudness of audio\n    - Control peaks in audio signals",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.Compress",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "threshold",
          "type": {
            "type": "float"
          },
          "default": -20.0,
          "title": "Threshold",
          "description": "Threshold in dB above which compression is applied.",
          "min": -60.0,
          "max": 0.0
        },
        {
          "name": "ratio",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Ratio",
          "description": "Compression ratio. Higher values result in more compression.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "attack",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Attack",
          "description": "Attack time in milliseconds.",
          "min": 0.1,
          "max": 100.0
        },
        {
          "name": "release",
          "type": {
            "type": "float"
          },
          "default": 50.0,
          "title": "Release",
          "description": "Release time in milliseconds.",
          "min": 5.0,
          "max": 1000.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "threshold",
        "ratio",
        "attack",
        "release"
      ]
    },
    {
      "title": "Delay",
      "description": "Applies a delay effect to an audio file.\n    audio, effect, time-based\n\n    Use cases:\n    - Create echo effects\n    - Add spaciousness to sounds\n    - Produce rhythmic patterns",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.Delay",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "delay_seconds",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Delay Seconds",
          "description": "Delay time in seconds.",
          "min": 0.01,
          "max": 5.0
        },
        {
          "name": "feedback",
          "type": {
            "type": "float"
          },
          "default": 0.3,
          "title": "Feedback",
          "description": "Amount of delayed signal fed back into the effect.",
          "min": 0.0,
          "max": 0.99
        },
        {
          "name": "mix",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Mix",
          "description": "Mix between the dry (original) and wet (delayed) signals.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "delay_seconds",
        "feedback",
        "mix"
      ]
    },
    {
      "title": "Distortion",
      "description": "Applies a distortion effect to an audio file.\n    audio, effect, distortion\n\n    Use cases:\n    - Add grit and character to instruments\n    - Create aggressive sound effects\n    - Simulate overdriven amplifiers",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.Distortion",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "drive_db",
          "type": {
            "type": "float"
          },
          "default": 25.0,
          "title": "Drive Db",
          "description": "Amount of distortion to apply in decibels.",
          "min": 0.0,
          "max": 100.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "drive_db"
      ]
    },
    {
      "title": "Gain",
      "description": "Applies a gain (volume adjustment) to an audio file.\n    audio, effect, volume\n\n    Use cases:\n    - Increase or decrease overall volume of audio\n    - Balance levels between different audio tracks\n    - Prepare audio for further processing",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.Gain",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "gain_db",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Gain Db",
          "description": "Gain to apply in decibels. Positive values increase volume, negative values decrease it.",
          "min": -60.0,
          "max": 24.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "gain_db"
      ]
    },
    {
      "title": "High Pass Filter",
      "description": "Applies a high-pass filter to attenuate frequencies below a cutoff point.\n    audio, effect, equalizer\n\n    Use cases:\n    - Remove low-frequency rumble or noise\n    - Clean up the low end of a mix\n    - Create filter sweep effects",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.HighPassFilter",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "cutoff_frequency_hz",
          "type": {
            "type": "float"
          },
          "default": 80.0,
          "title": "Cutoff Frequency Hz",
          "description": "The cutoff frequency of the high-pass filter in Hz.",
          "min": 20.0,
          "max": 5000.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "cutoff_frequency_hz"
      ]
    },
    {
      "title": "High Shelf Filter",
      "description": "Applies a high shelf filter to boost or cut high frequencies.\n    audio, effect, equalizer\n\n    Use cases:\n    - Enhance or reduce treble frequencies\n    - Add brightness or air to audio\n    - Tame harsh high frequencies",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.HighShelfFilter",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "cutoff_frequency_hz",
          "type": {
            "type": "float"
          },
          "default": 5000.0,
          "title": "Cutoff Frequency Hz",
          "description": "The cutoff frequency of the shelf filter in Hz.",
          "min": 1000.0,
          "max": 20000.0
        },
        {
          "name": "gain_db",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Gain Db",
          "description": "The gain to apply to the frequencies above the cutoff, in dB.",
          "min": -24.0,
          "max": 24.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "cutoff_frequency_hz",
        "gain_db"
      ]
    },
    {
      "title": "Limiter",
      "description": "Applies a limiter effect to an audio file.\n    audio, effect, dynamics\n\n    Use cases:\n    - Prevent audio clipping\n    - Increase perceived loudness without distortion\n    - Control dynamic range of audio",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.Limiter",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "threshold_db",
          "type": {
            "type": "float"
          },
          "default": -2.0,
          "title": "Threshold Db",
          "description": "Threshold in dB above which the limiter is applied.",
          "min": -60.0,
          "max": 0.0
        },
        {
          "name": "release_ms",
          "type": {
            "type": "float"
          },
          "default": 250.0,
          "title": "Release Ms",
          "description": "Release time in milliseconds.",
          "min": 1.0,
          "max": 1000.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "threshold_db",
        "release_ms"
      ]
    },
    {
      "title": "Low Pass Filter",
      "description": "Applies a low-pass filter to attenuate frequencies above a cutoff point.\n    audio, effect, equalizer\n\n    Use cases:\n    - Reduce high-frequency harshness\n    - Simulate muffled or distant sounds\n    - Create dub-style effects",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.LowPassFilter",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "cutoff_frequency_hz",
          "type": {
            "type": "float"
          },
          "default": 5000.0,
          "title": "Cutoff Frequency Hz",
          "description": "The cutoff frequency of the low-pass filter in Hz.",
          "min": 500.0,
          "max": 20000.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "cutoff_frequency_hz"
      ]
    },
    {
      "title": "Low Shelf Filter",
      "description": "Applies a low shelf filter to boost or cut low frequencies.\n    audio, effect, equalizer\n\n    Use cases:\n    - Enhance or reduce bass frequencies\n    - Shape the low-end response of audio\n    - Compensate for speaker or room deficiencies",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.LowShelfFilter",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "cutoff_frequency_hz",
          "type": {
            "type": "float"
          },
          "default": 200.0,
          "title": "Cutoff Frequency Hz",
          "description": "The cutoff frequency of the shelf filter in Hz.",
          "min": 20.0,
          "max": 1000.0
        },
        {
          "name": "gain_db",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Gain Db",
          "description": "The gain to apply to the frequencies below the cutoff, in dB.",
          "min": -24.0,
          "max": 24.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "cutoff_frequency_hz",
        "gain_db"
      ]
    },
    {
      "title": "Noise Gate",
      "description": "Applies a noise gate effect to an audio file.\n    audio, effect, dynamics\n\n    Use cases:\n    - Reduce background noise in recordings\n    - Clean up audio tracks with unwanted low-level sounds\n    - Create rhythmic effects by gating sustained sounds",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.NoiseGate",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "threshold_db",
          "type": {
            "type": "float"
          },
          "default": -50.0,
          "title": "Threshold Db",
          "description": "Threshold in dB below which the gate is active.",
          "min": -90.0,
          "max": 0.0
        },
        {
          "name": "attack_ms",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Attack Ms",
          "description": "Attack time in milliseconds.",
          "min": 0.1,
          "max": 100.0
        },
        {
          "name": "release_ms",
          "type": {
            "type": "float"
          },
          "default": 100.0,
          "title": "Release Ms",
          "description": "Release time in milliseconds.",
          "min": 5.0,
          "max": 1000.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "threshold_db",
        "attack_ms",
        "release_ms"
      ]
    },
    {
      "title": "Peak Filter",
      "description": "Applies a peak filter to boost or cut a specific frequency range.\n    audio, effect, equalizer\n\n    Use cases:\n    - Isolate specific frequency ranges\n    - Create telephone or radio voice effects\n    - Focus on particular instrument ranges in a mix",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.PeakFilter",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "cutoff_frequency_hz",
          "type": {
            "type": "float"
          },
          "default": 1000.0,
          "title": "Cutoff Frequency Hz",
          "description": "The cutoff frequency of the band-pass filter in Hz.",
          "min": 20.0,
          "max": 20000.0
        },
        {
          "name": "q_factor",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Q Factor",
          "description": "The Q factor, determining the width of the band. Higher values create narrower bands.",
          "min": 0.1,
          "max": 10.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "cutoff_frequency_hz",
        "q_factor"
      ]
    },
    {
      "title": "Phaser",
      "description": "Applies a phaser effect to an audio file.\n    audio, effect, modulation\n\n    Use cases:\n    - Create sweeping, swooshing sounds\n    - Add movement to static sounds\n    - Produce psychedelic or space-like effects",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.Phaser",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "rate_hz",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Rate Hz",
          "description": "Rate of the phaser effect in Hz.",
          "min": 0.1,
          "max": 10.0
        },
        {
          "name": "depth",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Depth",
          "description": "Depth of the phaser effect.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "centre_frequency_hz",
          "type": {
            "type": "float"
          },
          "default": 1300.0,
          "title": "Centre Frequency Hz",
          "description": "Centre frequency of the phaser in Hz.",
          "min": 100.0,
          "max": 5000.0
        },
        {
          "name": "feedback",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Feedback",
          "description": "Feedback of the phaser effect. Negative values invert the phase.",
          "min": -1.0,
          "max": 1.0
        },
        {
          "name": "mix",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Mix",
          "description": "Mix between the dry (original) and wet (effected) signals.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "rate_hz",
        "depth",
        "centre_frequency_hz",
        "feedback",
        "mix"
      ]
    },
    {
      "title": "Pitch Shift",
      "description": "Shifts the pitch of an audio file without changing its duration.\n    audio, effect, pitch\n\n    Use cases:\n    - Transpose audio to a different key\n    - Create harmonies or vocal effects\n    - Adjust instrument tuning",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.PitchShift",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "semitones",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Semitones",
          "description": "Number of semitones to shift the pitch. Positive values shift up, negative values shift down.",
          "min": -12.0,
          "max": 12.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "semitones"
      ]
    },
    {
      "title": "Reverb",
      "description": "Applies a reverb effect to an audio file.\n    audio, effect, reverb\n\n    Use cases:\n    - Add spatial depth to dry recordings\n    - Simulate different room acoustics\n    - Create atmospheric sound effects",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.Reverb",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "room_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Room Scale",
          "description": "Size of the simulated room. Higher values create larger spaces.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "damping",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Damping",
          "description": "Amount of high frequency absorption. Higher values create a duller sound.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "wet_level",
          "type": {
            "type": "float"
          },
          "default": 0.15,
          "title": "Wet Level",
          "description": "Level of the reverb effect in the output.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "dry_level",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Dry Level",
          "description": "Level of the original signal in the output.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "room_scale",
        "damping",
        "wet_level",
        "dry_level"
      ]
    },
    {
      "title": "Time Stretch",
      "description": "Changes the speed of an audio file without altering its pitch.\n    audio, transform, time\n\n    Use cases:\n    - Adjust audio duration to fit video length\n    - Create slow-motion or fast-motion audio effects\n    - Synchronize audio tracks of different lengths",
      "namespace": "lib.pedalboard",
      "node_type": "lib.pedalboard.TimeStretch",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process."
        },
        {
          "name": "rate",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Rate",
          "description": "Time stretch factor. Values > 1 speed up, < 1 slow down.",
          "min": 0.5,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "rate"
      ]
    },
    {
      "title": "Envelope",
      "description": "Applies an ADR (Attack-Decay-Release) envelope to an audio signal.\n    audio, synthesis, envelope\n\n    Use cases:\n    - Shape the amplitude of synthesized sounds\n    - Create percussion-like instruments\n    - Control sound dynamics",
      "namespace": "lib.synthesis",
      "node_type": "lib.synthesis.Envelope",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio to apply the envelope to."
        },
        {
          "name": "attack",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Attack",
          "description": "Attack time in seconds.",
          "min": 0.0,
          "max": 5.0
        },
        {
          "name": "decay",
          "type": {
            "type": "float"
          },
          "default": 0.3,
          "title": "Decay",
          "description": "Decay time in seconds.",
          "min": 0.0,
          "max": 5.0
        },
        {
          "name": "release",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Release",
          "description": "Release time in seconds.",
          "min": 0.0,
          "max": 5.0
        },
        {
          "name": "peak_amplitude",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Peak Amplitude",
          "description": "Peak amplitude after attack phase (0-1).",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "attack",
        "decay",
        "release",
        "peak_amplitude"
      ]
    },
    {
      "title": "FM Synthesis",
      "description": "Performs FM (Frequency Modulation) synthesis.\n    audio, synthesis, modulation\n\n    Use cases:\n    - Create complex timbres\n    - Generate bell-like sounds\n    - Synthesize metallic tones",
      "namespace": "lib.synthesis",
      "node_type": "lib.synthesis.FM_Synthesis",
      "properties": [
        {
          "name": "carrier_freq",
          "type": {
            "type": "float"
          },
          "default": 440.0,
          "title": "Carrier Freq",
          "description": "Carrier frequency in Hz.",
          "min": 20.0,
          "max": 20000.0
        },
        {
          "name": "modulator_freq",
          "type": {
            "type": "float"
          },
          "default": 110.0,
          "title": "Modulator Freq",
          "description": "Modulator frequency in Hz.",
          "min": 1.0,
          "max": 20000.0
        },
        {
          "name": "modulation_index",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Modulation Index",
          "description": "Modulation index (affects richness of sound).",
          "min": 0.0,
          "max": 100.0
        },
        {
          "name": "amplitude",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Amplitude",
          "description": "Amplitude of the output.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Duration",
          "description": "Duration in seconds.",
          "min": 0.0,
          "max": 30.0
        },
        {
          "name": "sample_rate",
          "type": {
            "type": "int"
          },
          "default": 44100,
          "title": "Sample Rate",
          "description": "Sampling rate in Hz."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "carrier_freq",
        "modulator_freq",
        "modulation_index",
        "amplitude",
        "duration",
        "sample_rate"
      ]
    },
    {
      "title": "Oscillator",
      "description": "Generates basic waveforms (sine, square, sawtooth, triangle).\n    audio, synthesis, waveform\n\n    Use cases:\n    - Create fundamental waveforms for synthesis\n    - Generate test signals\n    - Build complex sounds from basic waves",
      "namespace": "lib.synthesis",
      "node_type": "lib.synthesis.Oscillator",
      "properties": [
        {
          "name": "waveform",
          "type": {
            "type": "enum",
            "values": [
              "sine",
              "square",
              "sawtooth",
              "triangle"
            ],
            "type_name": "nodetool.nodes.lib.synthesis.Oscillator.OscillatorWaveform"
          },
          "default": "sine",
          "title": "Waveform",
          "description": "Type of waveform to generate (sine, square, sawtooth, triangle)."
        },
        {
          "name": "frequency",
          "type": {
            "type": "float"
          },
          "default": 440.0,
          "title": "Frequency",
          "description": "Frequency of the waveform in Hz.",
          "min": 20.0,
          "max": 20000.0
        },
        {
          "name": "amplitude",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Amplitude",
          "description": "Amplitude of the waveform.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Duration",
          "description": "Duration in seconds.",
          "min": 0.0,
          "max": 30.0
        },
        {
          "name": "sample_rate",
          "type": {
            "type": "int"
          },
          "default": 44100,
          "title": "Sample Rate",
          "description": "Sampling rate in Hz."
        },
        {
          "name": "pitch_envelope_amount",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Pitch Envelope Amount",
          "description": "Amount of pitch envelope in semitones",
          "min": -24.0,
          "max": 24.0
        },
        {
          "name": "pitch_envelope_time",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Pitch Envelope Time",
          "description": "Duration of pitch envelope in seconds",
          "min": 0.0,
          "max": 10.0
        },
        {
          "name": "pitch_envelope_curve",
          "type": {
            "type": "enum",
            "values": [
              "linear",
              "exponential"
            ],
            "type_name": "nodetool.nodes.lib.synthesis.PitchEnvelopeCurve"
          },
          "default": "linear",
          "title": "Pitch Envelope Curve",
          "description": "Shape of pitch envelope (linear, exponential)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "waveform",
        "frequency",
        "amplitude",
        "duration",
        "sample_rate",
        "pitch_envelope_amount",
        "pitch_envelope_time",
        "pitch_envelope_curve"
      ]
    },
    {
      "title": "Pink Noise",
      "description": "Generates pink noise (1/f noise).\n    audio, synthesis, noise\n\n    Use cases:\n    - Create natural-sounding background noise\n    - Test speaker response\n    - Sound masking",
      "namespace": "lib.synthesis",
      "node_type": "lib.synthesis.PinkNoise",
      "properties": [
        {
          "name": "amplitude",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Amplitude",
          "description": "Amplitude of the noise.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Duration",
          "description": "Duration in seconds.",
          "min": 0.0,
          "max": 30.0
        },
        {
          "name": "sample_rate",
          "type": {
            "type": "int"
          },
          "default": 44100,
          "title": "Sample Rate",
          "description": "Sampling rate in Hz."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "amplitude",
        "duration",
        "sample_rate"
      ]
    },
    {
      "title": "White Noise",
      "description": "Generates white noise.\n    audio, synthesis, noise\n\n    Use cases:\n    - Create background ambience\n    - Generate percussion sounds\n    - Test audio equipment",
      "namespace": "lib.synthesis",
      "node_type": "lib.synthesis.WhiteNoise",
      "properties": [
        {
          "name": "amplitude",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Amplitude",
          "description": "Amplitude of the noise.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Duration",
          "description": "Duration in seconds.",
          "min": 0.0,
          "max": 30.0
        },
        {
          "name": "sample_rate",
          "type": {
            "type": "int"
          },
          "default": 44100,
          "title": "Sample Rate",
          "description": "Sampling rate in Hz."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "amplitude",
        "duration",
        "sample_rate"
      ]
    },
    {
      "title": "Amplitude To DB",
      "description": "Converts an amplitude spectrogram to a dB-scaled spectrogram.\n    audio, analysis, spectrogram\n\n    This node is useful for:\n    - Compressing the dynamic range of spectrograms for visualization\n    - Preparing input for audio models that expect dB-scaled data",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.AmplitudeToDB",
      "properties": [
        {
          "name": "tensor",
          "type": {
            "type": "np_array"
          },
          "default": {
            "type": "np_array",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Tensor",
          "description": "The amplitude tensor to be converted to dB scale."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "tensor"
      ]
    },
    {
      "title": "Chroma STFT",
      "description": "This node creates a chromagram from a waveform or power spectrogram to identify different pitch classes in an audio signal.\n    audio, analysis, chromagram, pitch\n\n    Applications:\n    - Chord recognition in music\n    - Music genre classification based on pitch content",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.ChromaSTFT",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to extract chromagram from."
        },
        {
          "name": "n_fft",
          "type": {
            "type": "int"
          },
          "default": 2048,
          "title": "N Fft",
          "description": "The number of samples per frame.",
          "min": 0.0
        },
        {
          "name": "hop_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Hop Length",
          "description": "The number of samples between frames.",
          "min": 0.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "n_fft",
        "hop_length"
      ]
    },
    {
      "title": "DBTo Amplitude",
      "description": "The DBToAmplitude node Converts a dB-scaled spectrogram to an amplitude spectrogram.\n    audio, analysis, spectrogram\n    Useful for:\n    - Reversing dB scaling before audio synthesis\n    - Preparing data for models that expect linear amplitude scaling",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.DBToAmplitude",
      "properties": [
        {
          "name": "tensor",
          "type": {
            "type": "np_array"
          },
          "default": {
            "type": "np_array",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Tensor",
          "description": "The dB-scaled tensor to be converted to amplitude scale."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "tensor"
      ]
    },
    {
      "title": "DBTo Power",
      "description": "This node converts a decibel (dB) spectrogram back to power scale.\n    audio, analysis, spectrogram\n\n    Useful for:\n    - Reversing dB scaling for audio synthesis\n    - Preparing data for models that expect power-scaled data",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.DBToPower",
      "properties": [
        {
          "name": "tensor",
          "type": {
            "type": "np_array"
          },
          "default": {
            "type": "np_array",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Tensor",
          "description": "The tensor containing the decibel spectrogram."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "tensor"
      ]
    },
    {
      "title": "Griffin Lim",
      "description": "GriffinLim Node performs phase reconstruction on a magnitude spectrogram utilizing the Griffin-Lim algorithm.\n    audio, synthesis, phase reconstruction\n\n    Applications:\n    - Audio synthesis from spectrograms\n    - Phase reconstruction in audio processing pipelines",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.GriffinLim",
      "properties": [
        {
          "name": "magnitude_spectrogram",
          "type": {
            "type": "np_array"
          },
          "default": {
            "type": "np_array",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Magnitude Spectrogram",
          "description": "Magnitude spectrogram input for phase reconstruction."
        },
        {
          "name": "n_iter",
          "type": {
            "type": "int"
          },
          "default": 32,
          "title": "N Iter",
          "description": "Number of iterations for the Griffin-Lim algorithm."
        },
        {
          "name": "hop_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Hop Length",
          "description": "Number of samples between successive frames."
        },
        {
          "name": "win_length",
          "type": {
            "type": "int",
            "optional": true
          },
          "default": null,
          "title": "Win Length",
          "description": "Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`."
        },
        {
          "name": "window",
          "type": {
            "type": "str"
          },
          "default": "hann",
          "title": "Window",
          "description": "Type of window to use for Griffin-Lim transformation."
        },
        {
          "name": "center",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Center",
          "description": "If True, the signal `y` is padded so that frame `D[:, t]` is centered at `y[t * hop_length]`."
        },
        {
          "name": "length",
          "type": {
            "type": "int",
            "optional": true
          },
          "default": null,
          "title": "Length",
          "description": "If given, the resulting signal will be zero-padded or clipped to this length."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "magnitude_spectrogram",
        "n_iter",
        "hop_length",
        "win_length",
        "window",
        "center",
        "length"
      ]
    },
    {
      "title": "MFCC",
      "description": "MFCC Node computes the Mel-frequency cepstral coefficients (MFCCs) from an audio signal.\n    audio, analysis, frequency, MFCC, MEL",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.MFCC",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to extract MFCCs from."
        },
        {
          "name": "n_mfcc",
          "type": {
            "type": "int"
          },
          "default": 13,
          "title": "N Mfcc",
          "description": "The number of MFCCs to extract.",
          "min": 0.0
        },
        {
          "name": "n_fft",
          "type": {
            "type": "int"
          },
          "default": 2048,
          "title": "N Fft",
          "description": "The number of samples per frame.",
          "min": 0.0
        },
        {
          "name": "hop_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Hop Length",
          "description": "The number of samples between frames.",
          "min": 0.0
        },
        {
          "name": "fmin",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Fmin",
          "description": "The lowest frequency (in Hz).",
          "min": 0.0
        },
        {
          "name": "fmax",
          "type": {
            "type": "int"
          },
          "default": 8000,
          "title": "Fmax",
          "description": "The highest frequency (in Hz).",
          "min": 0.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "n_mfcc",
        "n_fft"
      ]
    },
    {
      "title": "Mel Spectrogram",
      "description": "MelSpecNode computes the Mel-frequency spectrogram for an audio signal.\n    audio, analysis, spectrogram\n\n    Useful for:\n    - Audio feature extraction for machine learning\n    - Speech and music analysis tasks",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.MelSpectrogram",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to convert to a tensor."
        },
        {
          "name": "n_fft",
          "type": {
            "type": "int"
          },
          "default": 2048,
          "title": "N Fft",
          "description": "The number of samples per frame.",
          "min": 0.0
        },
        {
          "name": "hop_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Hop Length",
          "description": "The number of samples between frames.",
          "min": 0.0
        },
        {
          "name": "n_mels",
          "type": {
            "type": "int"
          },
          "default": 128,
          "title": "N Mels",
          "description": "The number of Mel bands to generate.",
          "min": 0.0
        },
        {
          "name": "fmin",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Fmin",
          "description": "The lowest frequency (in Hz).",
          "min": 0.0
        },
        {
          "name": "fmax",
          "type": {
            "type": "int"
          },
          "default": 8000,
          "title": "Fmax",
          "description": "The highest frequency (in Hz).",
          "min": 0.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "n_mels",
        "fmax"
      ]
    },
    {
      "title": "Plot Spectrogram",
      "description": "The PlotSpectrogram node generates a visual representation of the spectrum of frequencies in an audio signal as they vary with time.\n    audio, analysis, frequency, spectrogram\n\n    #### Applications\n    - Audio Analysis: Allows users to visually see the spectrum of frequencies in their data.\n    - Machine Learning: Used as a preprocessing step for feeding data into image-based ML models.\n    - Sound engineering: Helps in identifying specific tones or frequencies in a music piece or a sound bite.",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.PlotSpectrogram",
      "properties": [
        {
          "name": "tensor",
          "type": {
            "type": "np_array"
          },
          "default": {
            "type": "np_array",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Tensor",
          "description": "The tensor containing the mel spectrogram."
        },
        {
          "name": "fmax",
          "type": {
            "type": "int"
          },
          "default": 8000,
          "title": "Fmax",
          "description": "The highest frequency (in Hz).",
          "min": 0.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "tensor",
        "fmax"
      ]
    },
    {
      "title": "Powert To DB",
      "description": "Converts a power spectrogram to decibel (dB) scale.\n    audio, analysis, decibel, spectrogram",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.PowertToDB",
      "properties": [
        {
          "name": "tensor",
          "type": {
            "type": "np_array"
          },
          "default": {
            "type": "np_array",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Tensor",
          "description": "The tensor containing the power spectrogram."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "tensor"
      ]
    },
    {
      "title": "STFT",
      "description": "This node computes the Short-Time Fourier Transform (STFT) matrix for an audio signal. The STFT matrix represents the signal in both time and frequency domains, forming the foundation for many audio processing tasks.\n    audio, analysis, fourier, frequency, time\n    #### Applications\n    - Audio Analysis: By transforming the audio signal into a visualizable format, it helps in understanding and analyzing the audio signal.\n    - Sound Processing: It plays a key foundational role in sound effects, tuning, compression, and more.\n    - Audio Feature Extraction: It can be used to analyze frequency-based features for sound classification.\n    - Music Information Retrieval: It helps in music transcription, rhythm and tempo analysis.",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.STFT",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to compute the STFT matrix from."
        },
        {
          "name": "n_fft",
          "type": {
            "type": "int"
          },
          "default": 2048,
          "title": "N Fft",
          "description": "The number of samples per frame.",
          "min": 0.0
        },
        {
          "name": "hop_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Hop Length",
          "description": "The number of samples between frames.",
          "min": 0.0
        },
        {
          "name": "win_length",
          "type": {
            "type": "int",
            "optional": true
          },
          "default": null,
          "title": "Win Length",
          "description": "The window length. If None, it defaults to n_fft."
        },
        {
          "name": "window",
          "type": {
            "type": "str"
          },
          "default": "hann",
          "title": "Window",
          "description": "The type of window to use."
        },
        {
          "name": "center",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Center",
          "description": "If True, input signal is padded so that frame D[:, t] is centered at y[t * hop_length]."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "n_fft",
        "hop_length"
      ]
    },
    {
      "title": "Spectral Centroid",
      "description": "Computes the spectral centroid of an audio file.\n    audio, analysis, spectral\n\n    The spectral centroid indicates where the \"center of mass\" of the spectrum is located.\n    Perceptually, it has a connection with the impression of \"brightness\" of a sound.\n\n    Use cases:\n    - Analyze the timbral characteristics of audio\n    - Track changes in sound brightness over time\n    - Feature extraction for music genre classification\n    - Audio effect design and sound manipulation",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.SpectralCentroid",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to analyze."
        },
        {
          "name": "n_fft",
          "type": {
            "type": "int"
          },
          "default": 2048,
          "title": "N Fft",
          "description": "The length of the FFT window.",
          "min": 128.0,
          "max": 8192.0
        },
        {
          "name": "hop_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Hop Length",
          "description": "Number of samples between successive frames.",
          "min": 64.0,
          "max": 2048.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "n_fft",
        "hop_length"
      ]
    },
    {
      "title": "Spectral Contrast",
      "description": "The spectral contrast measures the difference in amplitude between the most noticeable parts (peaks) and the less noticeable parts (valleys) in a sound spectrum.\n    audio, analysis, decibel, amplitude\n\n    #### Applications\n    - Music genre classification: distinguishing between different types of music based on the color of sound.\n    - Instrument recognition: recognizing different musical instruments by the difference in their spectral contrast.\n    - Audio analysis: determining various characteristics of audio files.\n\n    Useful note: The `n_fft` and `hop_length` parameters affect the resolution of the analysis. A higher `n_fft` provides better frequency resolution but worse time resolution, and vice versa for a lower `hop_length`.",
      "namespace": "lib.librosa.analysis",
      "node_type": "lib.librosa.analysis.SpectralContrast",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to extract spectral contrast from."
        },
        {
          "name": "n_fft",
          "type": {
            "type": "int"
          },
          "default": 2048,
          "title": "N Fft",
          "description": "The number of samples per frame.",
          "min": 0.0
        },
        {
          "name": "hop_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Hop Length",
          "description": "The number of samples between frames.",
          "min": 0.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "n_fft",
        "hop_length"
      ]
    },
    {
      "title": "Detect Onsets",
      "description": "Detect onsets in an audio file.\n    audio, analysis, segmentation\n\n    Use cases:\n    - Identify beat locations in music\n    - Segment audio based on changes in energy or spectral content\n    - Prepare audio for further processing or analysis",
      "namespace": "lib.librosa.segmentation",
      "node_type": "lib.librosa.segmentation.DetectOnsets",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The input audio file to analyze."
        },
        {
          "name": "hop_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Hop Length",
          "description": "Number of samples between successive frames."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "hop_length"
      ]
    },
    {
      "title": "Save Audio Segments",
      "description": "Save a list of audio segments to a specified folder.\n    audio, save, export\n\n    Use cases:\n    - Export segmented audio files for further processing or analysis\n    - Create a dataset of audio clips from a longer recording\n    - Organize audio segments into a structured format",
      "namespace": "lib.librosa.segmentation",
      "node_type": "lib.librosa.segmentation.SaveAudioSegments",
      "properties": [
        {
          "name": "segments",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "audio"
              }
            ]
          },
          "default": [],
          "title": "Segments",
          "description": "The list of audio segments to save."
        },
        {
          "name": "output_folder",
          "type": {
            "type": "folder"
          },
          "default": {
            "type": "folder",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Output Folder",
          "description": "The folder to save the audio segments in."
        },
        {
          "name": "name_prefix",
          "type": {
            "type": "str"
          },
          "default": "segment",
          "title": "Name Prefix",
          "description": "Prefix for the saved audio file names."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "folder"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "segments",
        "output_folder",
        "name_prefix"
      ]
    },
    {
      "title": "Segment Audio By Onsets",
      "description": "Segment an audio file based on detected onsets.\n    audio, segmentation, processing\n\n    Use cases:\n    - Split a long audio recording into individual segments\n    - Prepare audio clips for further analysis or processing\n    - Extract specific parts of an audio file based on onset locations",
      "namespace": "lib.librosa.segmentation",
      "node_type": "lib.librosa.segmentation.SegmentAudioByOnsets",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The input audio file to segment."
        },
        {
          "name": "onsets",
          "type": {
            "type": "np_array"
          },
          "default": {
            "type": "np_array",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Onsets",
          "description": "The onset times detected in the audio."
        },
        {
          "name": "min_segment_length",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Min Segment Length",
          "description": "Minimum length of a segment in seconds."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "audio"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "onsets",
        "min_segment_length"
      ]
    }
  ],
  "assets": [
    {
      "package_name": "nodetool-lib-audio",
      "name": "Segment Audio.jpg",
      "path": ""
    }
  ],
  "examples": [
    {
      "id": "fb81e4def50511efb8e900003278d4da",
      "name": "Segment Audio",
      "description": "This example demonstrates how to automatically segment an audio file based on detected onsets (sudden changes in audio intensity). The workflow first loads an audio file, then uses librosa's onset detection to identify points where new sounds begin. These onset points are used to slice the original audio into separate segments, which are then saved as individual files. This technique is useful for breaking down longer audio recordings into meaningful chunks for further processing, analysis, or organization. Common applications include splitting music into individual notes, separating speech into words or phrases, or isolating sound effects from a continuous recording.",
      "tags": [
        "audio"
      ]
    }
  ]
}